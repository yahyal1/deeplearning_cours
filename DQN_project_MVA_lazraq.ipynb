{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import random\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from keras.models import Sequential, model_from_json, Model\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Input, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject #3: Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self,s,train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The epsilon only intervenes on the training phase. Epsilon corresponds to the probability that the agent discover a new state and not use a previous best known action. Setting well epsilon will help to better explore unknown state and imporove current knowledge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=50 # set small when debugging\n",
    "epochs_test=5 # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The array ```position``` allows to track the position of the agent. It is updated at each step. \n",
    "> The array ```board``` correponds to the environment with the cheese and the poisonous cells and it is updated too at each step while t <= T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def learned_act(self, s): # the idea is to take a random integer between 0 and 4 \n",
    "        return np.random.randint(low = 0, high = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent,env,epochs,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "     \n",
    "        \n",
    "    for e in range(epochs): \n",
    "        state = env.reset() # At each epoch, we restart to a fresh game and get the initial state\n",
    "        game_over = False # This assumes that the games will end\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        \n",
    "        while not game_over : \n",
    "            action = agent.act(state) # The agent performs an action\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action) #Apply an action to the environment, get the next state, the reward\n",
    "            if reward > 0: # Update the counters\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "        \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 11.0/14.0. Average score (-3.0)\n",
      "Win/lose count 11.5/16.0. Average score (-3.75)\n",
      "Win/lose count 9.0/12.0. Average score (-3.5)\n",
      "Win/lose count 12.5/15.0. Average score (-3.25)\n",
      "Win/lose count 10.5/16.0. Average score (-3.7)\n",
      "Final score: -3.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAGPptZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1NSByMjkxNyAwYTg0ZDk4IC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxOCAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MToweDExMSBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MCBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD00IHRocmVhZHM9NiBsb29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAALrZYiEADf//vaH+BTZWBP+Wb/9DX/cj9uPrP1xYyEE31qvIejAGS+1H+b/rFFs6Z6UB/fgCJQAc24ZwpHZJ3jjhJSYReqPgUuAn34FNJkRcB7bUn4Utkjk+f5R4dvvEHd4xS5oKtD4BMvXGhlH9L0o30eDkQYAVfG8Db4m1slhDh5vNfvS6II4IMFa7qa18/BHSgPunBPnNqik9voVmOftByU+LiKrWqaAqdkUU985S0CI46eyBdBTukzoYPMlIosKOWDHMf1zu/Is7qTbf3LD9jPUXpsEGoBkqJjAIdSswjsf1MdUPJaCAsI5vi1rUCLjejuO7LFjjTdWtk3al1RqCYlDTnEBTkgjIFjpf6boRXu3DcmuTvLTr8puYAA8UINiRd5BouBN/rF0ubsPapcAF3ECrrsYanBUyrw07uA6ovVFSDPV4RFkDKurPH4Zgaaxo7gFqJ7YnB/RXRtdyAu+3R9FNEGOQq7fE9ho0BoqGNa0cBprgjeaqlhK8NfhyGpdWv4Da8yqsfBKHFV0Rosr6YYpPoJt3RyKS0wTOkb33TMPYdotfMJYfx8jgAYzFZVS5s2GLtfkXHW5px8co7SxnjxVLgbgQ7hQDQF6aALLwO1n9QcC10M5+69R4rlIk1HOL7NNvdZnjFupQa2RoYjuIu2CiZS6jOAtoT9EeY6Vb5p00gGhK4K5+MdwS0PCDKRLJHMcW2is+zMsbCnDu215dui26KT6xgRZmI/aVYN3pQWtLrEgoyCtjv1puBoaLBKqRw32VExOjmQEYFoc3S4wQQhCUawKCHrGvDVUZdxJbLrGWABrt7EyzWVeeAT5IAIp96qbpVbDKseg8izY3g9BZyKQCQ6Iz+9oh5yXp86B2CmZ8wGWhYaj3e9I7olSNUZWt1/j7uaFYkfJE57X/Gv5eK9ZKVwBofAgbDsPIKz8Nfp2Pm48NGEmMsQj4Ux6+PoJoiJIIFtnQuwynT57711VNoT++bO4E3WsAGrBAAAAEUGaJGxDf/6nhAAHy99n20zAAAAADEGeQniF/wAEtoA1YQAAABABnmF0Qr8ACdWUd+AD7jZAAAAADwGeY2pCvwAKOo0QWo8waQAAABlBmmdJqEFomUwIZ//+nhAASU4Rz+HOb66PAAAAD0GehUURLCv/AA8wP+bJIQAAAA0BnqZqQr8ADzWBQNTXAAAAGUGaqEmoQWyZTAhv//6nhAAS1bIJCAQWo4AAAAAfQZrKSeEKUmUwUVLDP/6eEABr191xHP6R19+0ZbV/MAAAABABnulqQr8AFrsiE3GfXqL5AAAAGEGa60nhDomUwIb//qeEABu/YPXsz4IstwAAABlBmwxJ4Q8mUwIb//6nhAAbH32Y/w+rbmWAAAAAGEGbL0nhDyZTAhv//qeEABr7SmX+fYWYIQAAAA9Bn01FETwr/wAWJrcNvcEAAAANAZ9uakK/ABYuUi3t7wAAABpBm3BJqEFomUwIb//+p4QAGx99n1HGhIc9IAAAAB9Bm5JJ4QpSZTBREsO//qmWAAjPx5/IvSPqhZCmGu0gAAAADwGfsWpCvwAOKD+qRQJW0wAAABtBm7ZJ4Q6JlMCG//6nhAALH8afyTUmmnpthyAAAAAQQZ/URRU8L/8ABplXjewZ+AAAAA8Bn/N0Qr8ACO2jFwH5qMEAAAAQAZ/1akK/AAktrXb2sMlM4AAAAB5Bm/lJqEFomUwIb//+p4QAB8vWG5lliZHfDzza9XcAAAASQZ4XRREsK/8ABnHeg3hss3N9AAAAEAGeOGpCvwAGcdU8lzPlRIAAAAAaQZo6SahBbJlMCG///qeEAAw9In+q3zH4w8EAAAAbQZpdSeEKUmUwIb/+p4QAEtQBZttn2eLZdbpYAAAAEkGee0U0TCv/AA8zO+hbkitZgQAAAA4BnpxqQr8ADzM8WtetZwAAACBBmoFJqEFomUwIb//+p4QAHR99n3a1bctOj9apkJHLHAAAABZBnr9FESwv/wAR3HjpnFD6cqGpd5/AAAAAEAGe3nRCvwAYiRZV4EV3lIEAAAAQAZ7AakK/ABiCW068AUBAgAAAAB9BmsNJqEFsmUwUTDP//p4QAE2kcs1olQxClvrr7eehAAAAEAGe4mpCvwAP4zwLr9YpTyAAAAAYQZrkSeEKUmUwIb/+p4QAE+BQV5chzqmBAAAAGUGbBUnhDomUwIb//qeEAAzvsH+E4LdCrsEAAAAaQZspSeEPJlMCG//+p4QADI2DVmTv2D/Q4sEAAAAQQZ9HRRE8L/8AB206jewYzQAAAA8Bn2Z0Qr8ABsElEKYJR4AAAAAQAZ9oakK/AAqCjRMiaVoSwAAAABlBm2pJqEFomUwIb//+p4QADJ+wevZnwRcbAAAAHUGbjEnhClJlMFESw3/+p4QAElHzVNZtzXjp9rn4AAAAEAGfq2pCvwAO2z5jdDkg6jgAAAAcQZuuSeEOiZTBRMO//qmWAA3kFnKDNAp9GP0zywAAABABn81qQr8AF0UaJkTSs7lBAAAAEUGb0knhDyZTAhv//qeEAAEnAAAADEGf8EURPC//AACygAAAAA8Bng90Qr8AFnso4jsuy38AAAAQAZ4RakK/ACK2td1kMOT9gQAAABxBmhRJqEFomUwU8N/+p4QAG79g/zyCtUyEi4FYAAAAEAGeM2pCvwAXSlG80xVtVCAAAAARQZo4SeEKUmUwIZ/+nhAABH0AAAAMQZ5WRTRML/8AALKAAAAAEAGedXRCvwAOsob2XVfwdEEAAAAQAZ53akK/ABdI2u6yGHKlQQAAABlBmnlJqEFomUwIZ//+nhAASUQ4/ngv5Is0AAAAGEGamknhClJlMCGf/p4QAEtEOP54L+SLDQAAABtBmrtJ4Q6JlMCG//6nhAAdo4z/Vb6qBCf3aOAAAAAYQZrcSeEPJlMCG//+p4QALn6J/qUgFXbBAAAAGUGa/0nhDyZTAhv//qeEAC6/GnQVrMpr6YEAAAAPQZ8dRRE8K/8AJbJuGyzAAAAAEAGfPmpCvwAkSpHezx9vW4AAAAAWQZsjSahBaJlMCGf//p4QAK17pvsMmwAAABNBn0FFESwv/wAavcLf6KsK0Pb8AAAAEAGfYHRCvwAkrq0ZIeTedoEAAAAQAZ9iakK/ACS7EeS5nyV2gAAAABpBm2RJqEFsmUwIb//+p4QARVAFm22fZ81SQQAAAB9Bm4ZJ4QpSZTBRUsN//qeEAG5dWqY/1W+Y9zZdbAOBAAAAEAGfpWpCvwBa7HluGzam2oEAAAAcQZuoSeEOiZTBRMM//p4QAq9e5rjn82vr77bZUQAAAA8Bn8dqQr8AjuxHkwPXtx8AAAAYQZvJSeEPJlMCG//+p4QAtOK0ghE/y20TAAAAGUGb6knhDyZTAhv//qeEALX7qfqONCQ4ScEAAAAbQZoOSeEPJlMCG//+p4QAdH2D/LXS3OCaJ8psAAAAH0GeLEURPC//AEVoDZcI8Cmn5AcywDwcyyDe8uNEz4AAAAAQAZ5LdEK/AF+AUzyvyU2g8QAAABABnk1qQr8APiC851oYXlXBAAAAGkGaT0moQWiZTAhv//6nhAAyLq0ghE/y2/WBAAAAGEGacEnhClJlMCHf/qmWACcL92OCj5qTgAAAABdBmpNJ4Q6JlMCHf/6plgAnPx5+/pzRWwAAABJBnrFFETwr/wBiIaXd4FNQbcEAAAAOAZ7SakK/AGIJcZ34V24AAAAgQZrXSahBaJlMCG///qeEAE+DtI8y7fYP2/1pbZ5rSmAAAAAWQZ71RREsL/8AL8q7vbSkEdO1eAmqwQAAABABnxR0Qr8AKOnUnlfkptwQAAAAEAGfFmpCvwA/jPAuv7cPy6EAAAAaQZsZSahBbJlMFEw3//6nhABP/dT9zJWX770AAAAPAZ84akK/AD+A/qkUCVWfAAAAG0GbPUnhClJlMCG//qeEAEtHzVNZtzXjp9q9qQAAABBBn1tFNEwv/wAtbLFQgpaQAAAAEAGfenRCvwA80ZkR2LMUdUkAAAAPAZ98akK/ADzWBLlf4ApBAAAAGUGbf0moQWiZTBTw3/6nhABLvjp91w6Wr2oAAAAQAZ+eakK/ADzBEzTfSQcf8AAAABlBm4BJ4QpSZTAhv/6nhAAyfsH+E4LdCXHBAAAAGEGbo0nhDomUwIb//qeEAB/fYPXsz4IshwAAAA9Bn8FFETwr/wAaYjQNrcEAAAAOAZ/iakK/ABprBOc8vQIAAAAcQZvlSahBaJlMFPDv/qmWAA+vtL9nl+MM1toRPwAAAA8BngRqQr8AGcIvmbZkbLMAAAAZQZoISeEKUmUwId/+qZYADv+0vC1BP7A5oQAAAA9BniZFNEwr/wAYgjQNtMEAAAAPAZ5HakK/ABfrFgXX+CvAAAAAHEGaTEmoQWiZTAh3//6plgAOp7S/r+q1CyFLoHMAAAAVQZ5qRREsL/8AGmSS/M24md/c9yMdAAAAEAGeiXRCvwAjvqJE+LMUftAAAAAQAZ6LakK/ACOyuRV4AoAFgAAAABxBmpBJqEFsmUwIb//+p4QAEm+On3MjC2YoRzV1AAAAFUGerkUVLC//ABBcePosV2818eQftQAAABABns10Qr8AFrzRInxZikXxAAAAEAGez2pCvwAWttyKvAFAToAAAAAZQZrUSahBbJlMCG///qeEABJVtLmb3U+M1QAAABBBnvJFFSwv/wALFQIKUM85AAAADwGfEXRCvwAJbaMXAfmk4AAAABABnxNqQr8ADtsweTA9fA2AAAAAGkGbFUmoQWyZTAhv//6nhAASb46fUcaEh1tBAAAAGUGbNknhClJlMCHf/qmWAAYL2l/O6QphLbAAAAAdQZtaSeEOiZTAhv/+p4QAB5/YP8tfMCE/Og5GQc0AAAAQQZ94RRE8L/8ABJZ/u8oo0QAAABABn5d0Qr8ABkgELgPygB/gAAAADwGfmWpCvwAD+GodC0cdwQAAABpBm55JqEFomUwIb//+p4QAB5WAToF7qfMSgAAAABBBn7xFESwv/wAEloCDfKShAAAAEAGf23RCvwAGSkteB0ynlYEAAAAPAZ/dakK/AAZKxYF1/jpAAAAAGUGb30moQWyZTAhv//6nhAAHn9g9ezPgi/cAAAAYQZviSeEKUmUwIZ/+nhAALVwY5/DnN9fxAAAAEUGeAEU0TCv/AAluzv+jkivlAAAADwGeIWpCvwAJbsR5MD18bwAAABlBmiNJqEFomUwIZ//+nhAARU4Rz+HOb66uAAAAGUGaREnhClJlMCG//qeEABuaRP9VvmPxO6EAAAAZQZplSeEOiZTAhv/+p4QAKx6J/qt8x+JNwQAAABFBmolJ4Q8mUwIb//6nhAABJwAAABNBnqdFETwv/wAo6bOTNuHBLmmlAAAAEAGexnRCvwA3UiyrwIruO4AAAAAQAZ7IakK/ADdEdudaGF5gQAAAAB1BmstJqEFomUwU8N/+p4QAK17qfd5uvvrZihH7GwAAABABnupqQr8AIrJ851oYXozAAAAAGEGa7EnhClJlMCG//qeEABsfYPXsz4IswQAAACBBmw5J4Q6JlMFNEw7//qmWAA1XxCHz++OYgpgdFzigQQAAABABny1qQr8AFZbkMPoCQc+5AAAAGkGbMknhDyZTAhv//qeEABub7SPMu32D9dSxAAAAEEGfUEURPC//ABBc/ZuCFPAAAAAPAZ9vdEK/AA6DYGuvi+2AAAAAEAGfcWpCvwAWuwjyYHr3o4EAAAAcQZt0SahBaJlMFPDf/qeEACw4rVMf6t2+wfrlpAAAAA8Bn5NqQr8AI7sR5MD17p8AAAAcQZuWSeEKUmUwUsN//qeEAEVHzNTZtxm91Pi6pQAAABABn7VqQr8AOKzB5MD17jaAAAAAGEGbuUnhDomUwIb//qeEAEdHzHkYn+W3XwAAAA9Bn9dFFTwr/wA6AK4bBcEAAAAPAZ/4akK/AFrja7vu95wgAAAAHEGb+0moQWiZTBTw3/6nhABxAeHFjVD/fHTxb/kAAAAQAZ4aakK/AF0seW4bNqbVgAAAABxBmh1J4QpSZTBSw3/+p4QAtOK1TH+rdvsH6391AAAADwGePGpCvwCS7EeTA9e3FwAAABhBmj5J4Q6JlMCG//6nhAEUQBZtjFCUUkAAAAAZQZpfSeEPJlMCHf/+qZYA+SSEm2ujn1Ek4AAAACFBmmFJ4Q8mUwURPDv//qmWAyAqFkJNoZ0qjN/S2+JJKmEAAAAQAZ6AakK/Ah7tqG4z688MCAAAABZBmoVJ4Q8mUwId//6plgLl1H+5gKmBAAAAE0Geo0URPC//AZXnmIu8LLkRug4AAAAQAZ7CdEK/Ah4AAZJYnV2bgQAAAA8BnsRqQr8CHuqeTAqeuzcAAAAZQZrJSahBaJlMCHf//qmWAzfCj6d2ZtKIOQAAABBBnudFESwv/wGVn6VwQRSRAAAADwGfBnRCvwIek0dVnf1iwAAAAA8BnwhqQr8CHksco0h4Me0AAAAbQZsNSahBbJlMCG///qeEAcbsH+RCzBNEzaHhAAAAFUGfK0UVLC//APJ/FVP6ZxhIVe1MWAAAABABn0p0Qr8BWrR3lbKHo4GAAAAADwGfTGpCvwDcktKkUCVR3QAAABtBm09JqEFsmUwUTDf//qeEAQxQb4n+WyUuPP8AAAAQAZ9uakK/ANy6p5MD17a7gQAAACZBm3JJ4QpSZTAhv/6nhAEN+On3o3woXMsrnun4FKlo/ApnYG4JUwAAABJBn5BFNEwr/wDiK4NcfcpezhcAAAAQAZ+xakK/AOerg1x4q2jwYQAAAB5Bm7ZJqEFomUwIZ//+nhAC5d8HDUvv5pWVbi2SHHAAAAAQQZ/URREsL/8AcVNW6I+wmAAAABABn/N0Qr8AlrtSeV+SmzWxAAAADwGf9WpCvwCa2td33e8GwAAAABlBm/dJqEFsmUwIZ//+nhAC5cGOfpr2+JOBAAAAGEGaGEnhClJlMCG//qeEASRAFm2MUJRNwQAAABlBmjlJ4Q6JlMCG//6nhAEkQBZgx2ZNW1iwAAAAHUGaW0nhDyZTBRE8N//+p4QBHfo5+P5lmqa3MdZ9AAAAEAGeempCvwDngvOdaGF4i8AAAAAcQZp9SeEPJlMFPDf//qeEALX7qfuZGFsxQjl2LQAAABABnpxqQr8AksnznWhheLdBAAAAGEGagEnhDyZTAhn//p4QAbv19/IkR9YR6QAAAA9Bnr5FETwr/wBdG3Ak5cAAAAANAZ7fakK/AF05WHinLwAAABlBmsFJqEFomUwIZ//+nhABHviH9shj6wmBAAAAGUGa4knhClJlMCG//qeEAC/+wf4Tgt0Jd0EAAAAZQZsDSeEOiZTAhv/+p4QAHn9g/wnBboTdwAAAABxBmydJ4Q8mUwIZ//6eEABP/dN7gBynnL4irpVJAAAAE0GfRUURPC//ABLfETUEsJ51UEkAAAAPAZ9kdEK/ABnJLNwbJeSDAAAAEAGfZmpCvwAZwltOvAFAN4EAAAAbQZtpS6hCEFokRggoB/IB/YeAU8K//jhAABFwAAAAJQGfiGpCvwKvY+1BxN2qw0km5aqGByy1u80qIKKLsaqRAtKsecAAAAuwbW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAH5AAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAACtp0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAH5AAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAARAAAAEQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAB+QAAAEAAABAAAAAApSbWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAyAAABlABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAJ/W1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAACb1zdGJsAAAAlXN0c2QAAAAAAAAAAQAAAIVhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAARABEABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAL2F2Y0MB9AAN/+EAF2f0AA2RmygiEdCAAAADAIAAABkHihTLAQAFaOvjxEgAAAAYc3R0cwAAAAAAAAABAAAAygAAAgAAAAAUc3RzcwAAAAAAAAABAAAAAQAABYhjdHRzAAAAAAAAAK8AAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAAEAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAgAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAADAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAwAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAADAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAygAAAAEAAAM8c3RzegAAAAAAAAAAAAAAygAABaAAAAAVAAAAEAAAABQAAAATAAAAHQAAABMAAAARAAAAHQAAACMAAAAUAAAAHAAAAB0AAAAcAAAAEwAAABEAAAAeAAAAIwAAABMAAAAfAAAAFAAAABMAAAAUAAAAIgAAABYAAAAUAAAAHgAAAB8AAAAWAAAAEgAAACQAAAAaAAAAFAAAABQAAAAjAAAAFAAAABwAAAAdAAAAHgAAABQAAAATAAAAFAAAAB0AAAAhAAAAFAAAACAAAAAUAAAAFQAAABAAAAATAAAAFAAAACAAAAAUAAAAFQAAABAAAAAUAAAAFAAAAB0AAAAcAAAAHwAAABwAAAAdAAAAEwAAABQAAAAaAAAAFwAAABQAAAAUAAAAHgAAACMAAAAUAAAAIAAAABMAAAAcAAAAHQAAAB8AAAAjAAAAFAAAABQAAAAeAAAAHAAAABsAAAAWAAAAEgAAACQAAAAaAAAAFAAAABQAAAAeAAAAEwAAAB8AAAAUAAAAFAAAABMAAAAdAAAAFAAAAB0AAAAcAAAAEwAAABIAAAAgAAAAEwAAAB0AAAATAAAAEwAAACAAAAAZAAAAFAAAABQAAAAgAAAAGQAAABQAAAAUAAAAHQAAABQAAAATAAAAFAAAAB4AAAAdAAAAIQAAABQAAAAUAAAAEwAAAB4AAAAUAAAAFAAAABMAAAAdAAAAHAAAABUAAAATAAAAHQAAAB0AAAAdAAAAFQAAABcAAAAUAAAAFAAAACEAAAAUAAAAHAAAACQAAAAUAAAAHgAAABQAAAATAAAAFAAAACAAAAATAAAAIAAAABQAAAAcAAAAEwAAABMAAAAgAAAAFAAAACAAAAATAAAAHAAAAB0AAAAlAAAAFAAAABoAAAAXAAAAFAAAABMAAAAdAAAAFAAAABMAAAATAAAAHwAAABkAAAAUAAAAEwAAAB8AAAAUAAAAKgAAABYAAAAUAAAAIgAAABQAAAAUAAAAEwAAAB0AAAAcAAAAHQAAACEAAAAUAAAAIAAAABQAAAAcAAAAEwAAABEAAAAdAAAAHQAAAB0AAAAgAAAAFwAAABMAAAAUAAAAHwAAACkAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguMjAuMTAw\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent,env,epochs_test,prefix='random')\n",
    "HTML(display_videos('random0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that :\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that \n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Then : \n",
    "\n",
    "\\begin{aligned}\n",
    "Q^\\pi(s,a) &= E_{p^{\\pi}}[\\sum_{t = 0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a]\\\\\n",
    "&= r(s,a) + E_{p^{\\pi}}[\\sum_{t = 1}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\\\\n",
    "&= r(s,a) + \\gamma \\sum_{(s',a')} \\mathbb{P}(s_1 = s', a_1 = a' |s_0 = s, a_0=a) E_{p^{\\pi}}[\\sum_{t = 0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s',a_{0}=a'] \\\\\n",
    "&= r(s,a) + \\gamma \\sum_{(s',a')} p^{\\pi}(s',a'|s,a) Q^{\\pi}(s',a') \\\\\n",
    "&= r(s,a) + \\gamma E_{(s',a')\\sim p^{\\pi}(.|s,a)}[Q^{\\pi}(s',a')] \\\\\n",
    "&= E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{aligned} \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have then :\n",
    "\n",
    "\\begin{aligned}\n",
    "Q^*(s,a) &= \\max_{\\pi}Q^{\\pi}(s,a)\\\\\n",
    "&= \\max_{\\pi} E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\\\\\n",
    "&=r(s,a)+\\gamma \\max_{\\pi} E_{(s',a')\\sim p(.|s,a)} Q^{\\pi}(s',a')\\\\\n",
    "&= r(s,a)+\\gamma \\max_{\\pi ,a } E_{s'\\sim \\pi(.|s,a)}[Q^{\\pi}(s',a')]\\\\\n",
    "&= r(s,a)+\\gamma E_{s'\\sim \\pi^{*}(.|s,a)}[\\max_{a' }Q^{\\pi^{*}}(s',a')]\\\\\n",
    "&= E_{s'\\sim \\pi^{*}(.|s,a)}[r(s,a)+\\gamma \\max_a'Q^{*}(s',a')]\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One objectif could be to minize the distance between the optimal policy $\\pi^*$ and the one that we have. To do so, we would like to minimize the following : \n",
    "\n",
    "\\begin{aligned}\n",
    "L&=Q^{*}(s',a',\\theta)-Q(s,a,\\theta\\\\\n",
    "L&= E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')]-Q(s,a,\\theta)\\\\\n",
    "L&=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')-Q(s,a,\\theta)]\\\\\n",
    "\\end{aligned}\n",
    "\n",
    "We oculd then construct a loss function by introducing the norm : \n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "\n",
    "    def remember(self, m):\n",
    "        self.memory.append(m)\n",
    "        if len (self.memory) > self.max_memory : \n",
    "            self.memory = self.memory [1 : ]\n",
    "\n",
    "\n",
    "    def random_access(self):\n",
    "        return random.choice(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The pipeline we will use for training is given below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.99\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        return np.argmax(self.model.predict(s[np.newaxis,:,:,:]))\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
    "        target_q = np.zeros((self.batch_size, 4))\n",
    "        \n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            ######## FILL IN\n",
    "            [s_, n_s_, a_, r_, game_over_] = self.memory.random_access()\n",
    "            input_states[i] = s_\n",
    "            target_q[i] = self.model.predict(s_[ np.newaxis,:,:,:])\n",
    "            target_q[i, a_] = r_\n",
    "            \n",
    "            if not game_over_:\n",
    "                target_q[i, a_] += self.discount * np.max(self.model.predict(n_s_[ np.newaxis,:,:,:]))\n",
    "        ######## FILL IN\n",
    "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
    "        target_q = np.clip(target_q, -3, 3)\n",
    "\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "\n",
    "\n",
    "        return l\n",
    "\n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, *args, lr=0.1,**kwargs):\n",
    "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        input_x = Input(shape=(5,5,self.n_state))\n",
    "        x = Flatten()(input_x)\n",
    "        x = Dense(64, activation=\"relu\")(x)\n",
    "        x = Dense(4, activation=\"relu\")(x)\n",
    "        model = Model(inputs=input_x, outputs=x)\n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/050 | Loss 0.0198 | Win/lose count 9.0/16.0 (-7.0)\n",
      "Epoch 001/050 | Loss 0.0115 | Win/lose count 5.0/6.0 (-1.0)\n",
      "Epoch 002/050 | Loss 0.0149 | Win/lose count 3.5/8.0 (-4.5)\n",
      "Epoch 003/050 | Loss 0.0230 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 004/050 | Loss 0.0120 | Win/lose count 5.0/0 (5.0)\n",
      "Epoch 005/050 | Loss 0.0060 | Win/lose count 3.0/3.0 (0.0)\n",
      "Epoch 006/050 | Loss 0.0274 | Win/lose count 4.5/9.0 (-4.5)\n",
      "Epoch 007/050 | Loss 0.0047 | Win/lose count 0.5/1.0 (-0.5)\n",
      "Epoch 008/050 | Loss 0.0093 | Win/lose count 4.0/6.0 (-2.0)\n",
      "Epoch 009/050 | Loss 0.0086 | Win/lose count 3.5/4.0 (-0.5)\n",
      "Epoch 010/050 | Loss 0.0151 | Win/lose count 8.0/5.0 (3.0)\n",
      "Epoch 011/050 | Loss 0.0130 | Win/lose count 2.5/7.0 (-4.5)\n",
      "Epoch 012/050 | Loss 0.0184 | Win/lose count 4.0/1.0 (3.0)\n",
      "Epoch 013/050 | Loss 0.0070 | Win/lose count 5.5/5.0 (0.5)\n",
      "Epoch 014/050 | Loss 0.0030 | Win/lose count 1.5/0 (1.5)\n",
      "Epoch 015/050 | Loss 0.0103 | Win/lose count 3.5/6.0 (-2.5)\n",
      "Epoch 016/050 | Loss 0.0067 | Win/lose count 4.0/1.0 (3.0)\n",
      "Epoch 017/050 | Loss 0.0075 | Win/lose count 2.0/5.0 (-3.0)\n",
      "Epoch 018/050 | Loss 0.0101 | Win/lose count 7.0/4.0 (3.0)\n",
      "Epoch 019/050 | Loss 0.0121 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 020/050 | Loss 0.0143 | Win/lose count 4.5/2.0 (2.5)\n",
      "Epoch 021/050 | Loss 0.0030 | Win/lose count 4.5/2.0 (2.5)\n",
      "Epoch 022/050 | Loss 0.0043 | Win/lose count 6.0/0 (6.0)\n",
      "Epoch 023/050 | Loss 0.0244 | Win/lose count 4.5/0 (4.5)\n",
      "Epoch 024/050 | Loss 0.0092 | Win/lose count 2.0/3.0 (-1.0)\n",
      "Epoch 025/050 | Loss 0.0371 | Win/lose count 0.5/3.0 (-2.5)\n",
      "Epoch 026/050 | Loss 0.0039 | Win/lose count 10.0/7.0 (3.0)\n",
      "Epoch 027/050 | Loss 0.0091 | Win/lose count 6.0/2.0 (4.0)\n",
      "Epoch 028/050 | Loss 0.0022 | Win/lose count 9.5/5.0 (4.5)\n",
      "Epoch 029/050 | Loss 0.0035 | Win/lose count 6.0/5.0 (1.0)\n",
      "Epoch 030/050 | Loss 0.0016 | Win/lose count 10.5/3.0 (7.5)\n",
      "Epoch 031/050 | Loss 0.0102 | Win/lose count 2.5/2.0 (0.5)\n",
      "Epoch 032/050 | Loss 0.0059 | Win/lose count 5.5/5.0 (0.5)\n",
      "Epoch 033/050 | Loss 0.0038 | Win/lose count 3.0/5.0 (-2.0)\n",
      "Epoch 034/050 | Loss 0.0044 | Win/lose count 8.0/0 (8.0)\n",
      "Epoch 035/050 | Loss 0.0030 | Win/lose count 1.0/1.0 (0.0)\n",
      "Epoch 036/050 | Loss 0.0057 | Win/lose count 5.0/5.0 (0.0)\n",
      "Epoch 037/050 | Loss 0.0026 | Win/lose count 5.5/3.0 (2.5)\n",
      "Epoch 038/050 | Loss 0.0092 | Win/lose count 11.0/2.0 (9.0)\n",
      "Epoch 039/050 | Loss 0.0038 | Win/lose count 6.0/1.0 (5.0)\n",
      "Epoch 040/050 | Loss 0.0047 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 041/050 | Loss 0.0037 | Win/lose count 11.5/3.0 (8.5)\n",
      "Epoch 042/050 | Loss 0.0034 | Win/lose count 5.5/2.0 (3.5)\n",
      "Epoch 043/050 | Loss 0.0571 | Win/lose count 5.5/0 (5.5)\n",
      "Epoch 044/050 | Loss 0.0073 | Win/lose count 15.0/2.0 (13.0)\n",
      "Epoch 045/050 | Loss 0.0066 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 046/050 | Loss 0.0028 | Win/lose count 6.5/1.0 (5.5)\n",
      "Epoch 047/050 | Loss 0.0039 | Win/lose count 9.5/1.0 (8.5)\n",
      "Epoch 048/050 | Loss 0.0027 | Win/lose count 16.5/3.0 (13.5)\n",
      "Epoch 049/050 | Loss 0.0048 | Win/lose count 6.5/4.0 (2.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent, env, epochs_train, prefix='fc_train')\n",
    "HTML(display_videos('fc_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        input_x = Input(shape=(5,5,self.n_state))\n",
    "        x = Conv2D(32, kernel_size=(2, 2))(input_x)\n",
    "        x = Conv2D(16, kernel_size=(2, 2))(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(4, activation=\"relu\")(x)\n",
    "        model = Model(inputs=input_x, outputs=x)\n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/050 | Loss 0.0018 | Win/lose count 1.5/3.0 (-1.5)\n",
      "Epoch 001/050 | Loss 0.0049 | Win/lose count 6.0/5.0 (1.0)\n",
      "Epoch 002/050 | Loss 0.0256 | Win/lose count 6.0/5.0 (1.0)\n",
      "Epoch 003/050 | Loss 0.0216 | Win/lose count 4.5/2.0 (2.5)\n",
      "Epoch 004/050 | Loss 0.0090 | Win/lose count 8.0/1.0 (7.0)\n",
      "Epoch 005/050 | Loss 0.0019 | Win/lose count 6.5/1.0 (5.5)\n",
      "Epoch 006/050 | Loss 0.0039 | Win/lose count 4.0/1.0 (3.0)\n",
      "Epoch 007/050 | Loss 0.0024 | Win/lose count 7.5/1.0 (6.5)\n",
      "Epoch 008/050 | Loss 0.0026 | Win/lose count 2.5/1.0 (1.5)\n",
      "Epoch 009/050 | Loss 0.0017 | Win/lose count 8.0/1.0 (7.0)\n",
      "Epoch 010/050 | Loss 0.0010 | Win/lose count 14.0/5.0 (9.0)\n",
      "Epoch 011/050 | Loss 0.0025 | Win/lose count 17.0/3.0 (14.0)\n",
      "Epoch 012/050 | Loss 0.0032 | Win/lose count 18.0/5.0 (13.0)\n",
      "Epoch 013/050 | Loss 0.0019 | Win/lose count 15.0/3.0 (12.0)\n",
      "Epoch 014/050 | Loss 0.0016 | Win/lose count 11.5/1.0 (10.5)\n",
      "Epoch 015/050 | Loss 0.0037 | Win/lose count 5.5/0 (5.5)\n",
      "Epoch 016/050 | Loss 0.0520 | Win/lose count 10.0/2.0 (8.0)\n",
      "Epoch 017/050 | Loss 0.0062 | Win/lose count 11.5/4.0 (7.5)\n",
      "Epoch 018/050 | Loss 0.0013 | Win/lose count 8.5/3.0 (5.5)\n",
      "Epoch 019/050 | Loss 0.0036 | Win/lose count 19.5/4.0 (15.5)\n",
      "Epoch 020/050 | Loss 0.0022 | Win/lose count 19.5/3.0 (16.5)\n",
      "Epoch 021/050 | Loss 0.0023 | Win/lose count 14.5/3.0 (11.5)\n",
      "Epoch 022/050 | Loss 0.0616 | Win/lose count 4.5/2.0 (2.5)\n",
      "Epoch 023/050 | Loss 0.0449 | Win/lose count 12.5/2.0 (10.5)\n",
      "Epoch 024/050 | Loss 0.0041 | Win/lose count 8.5/4.0 (4.5)\n",
      "Epoch 025/050 | Loss 0.0030 | Win/lose count 22.5/2.0 (20.5)\n",
      "Epoch 026/050 | Loss 0.0020 | Win/lose count 9.0/3.0 (6.0)\n",
      "Epoch 027/050 | Loss 0.0030 | Win/lose count 10.5/1.0 (9.5)\n",
      "Epoch 028/050 | Loss 0.0008 | Win/lose count 13.0/5.0 (8.0)\n",
      "Epoch 029/050 | Loss 0.0017 | Win/lose count 12.5/0 (12.5)\n",
      "Epoch 030/050 | Loss 0.0017 | Win/lose count 18.5/1.0 (17.5)\n",
      "Epoch 031/050 | Loss 0.0025 | Win/lose count 9.0/1.0 (8.0)\n",
      "Epoch 032/050 | Loss 0.0017 | Win/lose count 10.5/1.0 (9.5)\n",
      "Epoch 033/050 | Loss 0.0021 | Win/lose count 11.5/2.0 (9.5)\n",
      "Epoch 034/050 | Loss 0.0040 | Win/lose count 5.0/1.0 (4.0)\n",
      "Epoch 035/050 | Loss 0.0032 | Win/lose count 10.5/1.0 (9.5)\n",
      "Epoch 036/050 | Loss 0.0025 | Win/lose count 25.5/0 (25.5)\n",
      "Epoch 037/050 | Loss 0.0008 | Win/lose count 8.0/1.0 (7.0)\n",
      "Epoch 038/050 | Loss 0.0024 | Win/lose count 8.5/5.0 (3.5)\n",
      "Epoch 039/050 | Loss 0.0010 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 040/050 | Loss 0.0566 | Win/lose count 12.5/2.0 (10.5)\n",
      "Epoch 041/050 | Loss 0.0009 | Win/lose count 11.5/3.0 (8.5)\n",
      "Epoch 042/050 | Loss 0.0010 | Win/lose count 15.0/1.0 (14.0)\n",
      "Epoch 043/050 | Loss 0.0019 | Win/lose count 16.0/2.0 (14.0)\n",
      "Epoch 044/050 | Loss 0.0026 | Win/lose count 20.5/3.0 (17.5)\n",
      "Epoch 045/050 | Loss 0.0591 | Win/lose count 14.5/4.0 (10.5)\n",
      "Epoch 046/050 | Loss 0.0061 | Win/lose count 8.0/3.0 (5.0)\n",
      "Epoch 047/050 | Loss 0.0025 | Win/lose count 20.0/2.0 (18.0)\n",
      "Epoch 048/050 | Loss 0.0618 | Win/lose count 8.5/3.0 (5.5)\n",
      "Epoch 049/050 | Loss 0.0044 | Win/lose count 12.5/5.0 (7.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent,env,epochs_train,prefix='cnn_train')\n",
    "HTML(display_videos('cnn_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of the CNN\n",
      "Win/lose count 5.0/1.0. Average score (4.0)\n",
      "Win/lose count 6.0/3.0. Average score (3.5)\n",
      "Win/lose count 7.0/1.0. Average score (4.333333333333333)\n",
      "Win/lose count 9.0/3.0. Average score (4.75)\n",
      "Win/lose count 11.5/3.0. Average score (5.5)\n",
      "Final score: 5.5\n",
      "Test of the FC\n",
      "Win/lose count 2.0/7.0. Average score (-5.0)\n",
      "Win/lose count 1.5/1.0. Average score (-2.25)\n",
      "Win/lose count 2.5/5.0. Average score (-2.3333333333333335)\n",
      "Win/lose count 3.0/7.0. Average score (-2.75)\n",
      "Win/lose count 3.0/4.0. Average score (-2.4)\n",
      "Final score: -2.4\n"
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
    "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
    "\n",
    "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
    "print('Test of the CNN')\n",
    "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
    "print('Test of the FC')\n",
    "test(agent_fc,env,epochs_test,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test4.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('fc_test4.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_explore(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "    epsilons = [0.9**i * 0.8 for i in range(epoch)]\n",
    "    \n",
    "    for e, epsilon in enumerate(epsilons):\n",
    "        agent.set_epsilon(epsilon)\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "        \n",
    "class EnvironmentExploring(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "        self.malus_position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y] + self.malus_position[self.x, self.y]          \n",
    "        self.board[self.x, self.y] = 0\n",
    "        self.malus_position[self.x, self.y] = -0.5\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.malus_position.reshape(self.grid_size,self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.malus_position[0: 2, :] = -1\n",
    "        self.malus_position[:, 0:2] = -1\n",
    "        self.malus_position[-2:, :] = -1\n",
    "        self.malus_position[-2:, :] = -1\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.malus_position.reshape(self.grid_size,self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state\n",
    "    \n",
    "# ## use those samples of code:\n",
    "# #In train explore:\n",
    "# state, reward, game_over = env.act(action, train=True)\n",
    "\n",
    "# ## In Environment exploring:\n",
    "# # You will have to change n_state to 3 because you will use one more layer!\n",
    "# reward = 0\n",
    "# if train:\n",
    "#     reward = -self.malus_position[self.x, self.y]\n",
    "# self.malus_position[self.x, self.y] = 0.1\n",
    "\n",
    "# reward = reward + self.board[self.x, self.y]\n",
    "# # 3 \"feature\" states instead of 2\n",
    "# state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "#                                 self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "#                         self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/050 | Loss 0.0222 | Win/lose count 11.5/74.5 (-63.0)\n",
      "Epoch 001/050 | Loss 0.0330 | Win/lose count 16.5/72.0 (-55.5)\n",
      "Epoch 002/050 | Loss 0.0324 | Win/lose count 12.0/73.0 (-61.0)\n",
      "Epoch 003/050 | Loss 0.0265 | Win/lose count 17.0/68.0 (-51.0)\n",
      "Epoch 004/050 | Loss 0.0218 | Win/lose count 17.0/61.0 (-44.0)\n",
      "Epoch 005/050 | Loss 0.0330 | Win/lose count 17.5/70.5 (-53.0)\n",
      "Epoch 006/050 | Loss 0.0311 | Win/lose count 19.5/57.0 (-37.5)\n",
      "Epoch 007/050 | Loss 0.0517 | Win/lose count 22.0/53.5 (-31.5)\n",
      "Epoch 008/050 | Loss 0.0477 | Win/lose count 13.5/58.5 (-45.0)\n",
      "Epoch 009/050 | Loss 0.0348 | Win/lose count 11.0/75.0 (-64.0)\n",
      "Epoch 010/050 | Loss 0.0438 | Win/lose count 22.0/59.5 (-37.5)\n",
      "Epoch 011/050 | Loss 0.0373 | Win/lose count 16.0/60.0 (-44.0)\n",
      "Epoch 012/050 | Loss 0.0470 | Win/lose count 16.5/66.5 (-50.0)\n",
      "Epoch 013/050 | Loss 0.0597 | Win/lose count 21.0/59.5 (-38.5)\n",
      "Epoch 014/050 | Loss 0.0572 | Win/lose count 20.0/59.5 (-39.5)\n",
      "Epoch 015/050 | Loss 0.0468 | Win/lose count 17.5/62.0 (-44.5)\n",
      "Epoch 016/050 | Loss 0.0582 | Win/lose count 17.5/70.0 (-52.5)\n",
      "Epoch 017/050 | Loss 0.0483 | Win/lose count 18.5/60.5 (-42.0)\n",
      "Epoch 018/050 | Loss 0.0605 | Win/lose count 19.0/56.5 (-37.5)\n",
      "Epoch 019/050 | Loss 0.0544 | Win/lose count 20.5/58.5 (-38.0)\n",
      "Epoch 020/050 | Loss 0.0468 | Win/lose count 7.5/82.5 (-75.0)\n",
      "Epoch 021/050 | Loss 0.0496 | Win/lose count 23.0/57.0 (-34.0)\n",
      "Epoch 022/050 | Loss 0.0471 | Win/lose count 22.5/56.5 (-34.0)\n",
      "Epoch 023/050 | Loss 0.0637 | Win/lose count 19.5/60.5 (-41.0)\n",
      "Epoch 024/050 | Loss 0.0438 | Win/lose count 20.0/58.5 (-38.5)\n",
      "Epoch 025/050 | Loss 0.0491 | Win/lose count 20.0/59.0 (-39.0)\n",
      "Epoch 026/050 | Loss 0.0732 | Win/lose count 20.0/61.5 (-41.5)\n",
      "Epoch 027/050 | Loss 0.0454 | Win/lose count 8.5/88.0 (-79.5)\n",
      "Epoch 028/050 | Loss 0.0607 | Win/lose count 18.0/64.5 (-46.5)\n",
      "Epoch 029/050 | Loss 0.0534 | Win/lose count 20.0/61.0 (-41.0)\n",
      "Epoch 030/050 | Loss 0.0470 | Win/lose count 17.0/65.5 (-48.5)\n",
      "Epoch 031/050 | Loss 0.0333 | Win/lose count 16.5/59.0 (-42.5)\n",
      "Epoch 032/050 | Loss 0.0521 | Win/lose count 18.5/61.0 (-42.5)\n",
      "Epoch 033/050 | Loss 0.0499 | Win/lose count 14.5/72.5 (-58.0)\n",
      "Epoch 034/050 | Loss 0.0455 | Win/lose count 12.5/73.0 (-60.5)\n",
      "Epoch 035/050 | Loss 0.0445 | Win/lose count 21.0/55.0 (-34.0)\n",
      "Epoch 036/050 | Loss 0.0485 | Win/lose count 16.0/66.0 (-50.0)\n",
      "Epoch 037/050 | Loss 0.0435 | Win/lose count 18.5/59.0 (-40.5)\n",
      "Epoch 038/050 | Loss 0.0452 | Win/lose count 17.0/61.5 (-44.5)\n",
      "Epoch 039/050 | Loss 0.0527 | Win/lose count 9.5/77.5 (-68.0)\n",
      "Epoch 040/050 | Loss 0.0580 | Win/lose count 11.5/80.5 (-69.0)\n",
      "Epoch 041/050 | Loss 0.0496 | Win/lose count 14.5/60.0 (-45.5)\n",
      "Epoch 042/050 | Loss 0.0464 | Win/lose count 14.0/70.5 (-56.5)\n",
      "Epoch 043/050 | Loss 0.0558 | Win/lose count 20.5/58.0 (-37.5)\n",
      "Epoch 044/050 | Loss 0.0455 | Win/lose count 10.0/80.0 (-70.0)\n",
      "Epoch 045/050 | Loss 0.0528 | Win/lose count 23.0/58.5 (-35.5)\n",
      "Epoch 046/050 | Loss 0.0361 | Win/lose count 20.5/57.5 (-37.0)\n",
      "Epoch 047/050 | Loss 0.0544 | Win/lose count 15.0/72.5 (-57.5)\n",
      "Epoch 048/050 | Loss 0.0463 | Win/lose count 16.0/65.5 (-49.5)\n",
      "Epoch 049/050 | Loss 0.0561 | Win/lose count 16.0/64.0 (-48.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32,n_state=3)\n",
    "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
    "HTML(display_videos('cnn_train_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
    "HTML(display_videos('cnn_test_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
